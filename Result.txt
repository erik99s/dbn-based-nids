Result

0        407353
1	 77792

'tp': 70596,  77792
'tn': 313000,  407353
'fp': 94353, 
'fn': 7196, 
'precision': 0.43,
'recall': 0.91 
'f1_score': 0.58


0	164463	 
1	486

'tp': 477, 486
'tn': 131950, 164463
'fp': 32513, 
'fn': 9, 
'precision': 0.014, 
'recall': 0.98,
'f1_score': 0.038,


'tp': 475, 'tn': 135247, 'fp': 29216, 'fn': 11, 'accuracy': 0.8228118994355831, 'precision': 0.015998113906565626, 'recall': 0.9773662551239225, 'f1_score': 0.03148092886754517}}




threshold: 0.0345888577401638
values:  tp: 72908 tn: 334717 fp: 72636 fn: 4884
Saved anomalous samples to anomalous_features.pkl and anomalous_labels.pkl
{'test': {'avg_test_loss': 0.02861352781320709, 'tp': 72908, 'tn': 334717, 'fp': 72636, 'fn': 4884, 'accuracy': 0.840212719908481, 'precision': 0.5009344253283886, 'recall': 0.9372171945700153, 'f1_score': 0.6528996623297382}}

0        72636
2        59770
3        11503
1         1138
4          497
dtype: int64

 
threshold: 0.0804539482295513
values:  tp: 476 tn: 119325 fp: 25722 fn: 21
Test Loss: 0.047860
precision: 0.01816932590273373
recall: 0.9577464788539689
f1 score: 0.035662108643729054
{'test': {'avg_test_loss': 0.0478600168937984, 'tp': 476, 'tn': 119325, 'fp': 25722, 'fn': 21, 'accuracy': 0.823125652723575, 'precision': 0.01816932590273373, 'recall': 0.9577464788539689, 'f1_score': 0.035662108643729054}}

0        407353
2         63698
3         11527
1          1757
4           810


0        72636
2        59770
3        11503
1         1138
4          497
